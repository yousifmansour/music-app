{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense\n",
    "import numpy as np\n",
    "\n",
    "units = 1000\n",
    "\n",
    "'layer 1 is the encoder'\n",
    "encoder_inputs = Input(shape=(None, 15))\n",
    "encoder = LSTM(units, return_state=True)\n",
    "encoder_outputs, encoder_state_h, encoder_state_c = encoder(encoder_inputs)\n",
    "'encoder_outputs wont be used'\n",
    "\n",
    "'layer 2 is the decoder'\n",
    "decoder_inputs = Input(shape=(None, 15))\n",
    "decoder = LSTM(units, return_sequences=True, return_state=True)\n",
    "decoder_outputs, decoder_state_h, decoder_state_c = decoder(decoder_inputs, initial_state=[encoder_state_h, encoder_state_c])\n",
    "\n",
    "'layer 3 is a softmax layer for output'\n",
    "decoder_dense = Dense(15, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=[keras.metrics.categorical_accuracy])\n",
    "\n",
    "encoder_model = keras.Model(encoder_inputs, [encoder_state_h, encoder_state_c])\n",
    "\n",
    "decoder_state_input_h = Input(shape=(units,))\n",
    "decoder_state_input_c = Input(shape=(units,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "decoder_outputs, state_h, state_c = decoder(decoder_inputs, initial_state=decoder_states_inputs)\n",
    "\n",
    "decoder_states = [state_h, state_c]\n",
    "\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "decoder_model = keras.Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)\n",
    "\n",
    "'function to take sequence of note values and return another one'\n",
    "'input_seq is (1, 128, 57)'\n",
    "'output is (128, 57)'\n",
    "\n",
    "\n",
    "model.load_weights('lstm_units_1000_batch_64_whole_dataset.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_notes_to_one_octave(note_values):\n",
    "    output = np.array(note_values)\n",
    "    for i in range(0, len(note_values)):\n",
    "        note = note_values[i]\n",
    "        if(note == 0):\n",
    "            output[i] = -1\n",
    "        else:\n",
    "            output[i] = note%12\n",
    "    return output\n",
    "    \n",
    "def decode_sequence(input_seq):\n",
    "    'run encoder to get the state that will be input for the decoder'\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    \n",
    "    'decode starts start of sequence vector'\n",
    "    target = np.zeros((1, 1, 15))\n",
    "    target[0, 0, 13] = 1\n",
    "    \n",
    "    'decoded_sequence contains notes in the output'\n",
    "    decoded_sequence = np.zeros((number_of_notes, 15))\n",
    "        \n",
    "    'loop generates 64 notes'\n",
    "    for i in range(0, number_of_notes):\n",
    "        'running decoder to predict next value given target note and input state'\n",
    "        output_note, h, c = decoder_model.predict([target] + states_value)\n",
    "        \n",
    "        'getting note with highest softmax value'\n",
    "        note_index = np.argmax(output_note)\n",
    "        \n",
    "        'updating output sequence'\n",
    "        decoded_sequence[i, note_index] = 1 \n",
    "        \n",
    "        'setting next target to be the previous note'\n",
    "        target = np.zeros((1, 1, 15))            \n",
    "        target[0, 0, note_index] = 1\n",
    "        'updating the decoder input for next iteration'\n",
    "        states_value = [h, c]\n",
    "        \n",
    "    return decoded_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "'''read input sequence and write an output sequence that can later be transformed into midi'''\n",
    "\n",
    "def note_values_to_one_hot_phrase(note_values):\n",
    "    note_values = map_notes_to_one_octave(note_values)\n",
    "    ''' 12 is 0, 13 is start, 14 is end '''\n",
    "    ''' values are between 0 and 11'''\n",
    "    one_hot_phrase = np.zeros((number_of_notes+2, 15))\n",
    "    'start of sequence'\n",
    "    one_hot_phrase[0][13] = 1 \n",
    "    for i in range (1, len(note_values)+1):\n",
    "        note = int(note_values[i-1])\n",
    "        one_hot_note = np.zeros(15)\n",
    "        if(note == -1):\n",
    "            one_hot_note[12] = 1\n",
    "        else:\n",
    "            one_hot_note[note] = 1\n",
    "        one_hot_phrase[i] = one_hot_note\n",
    "    'end of sequence'\n",
    "    one_hot_phrase[-1][14] = 1 \n",
    "        \n",
    "    return one_hot_phrase\n",
    "\n",
    "def one_hot_phrase_to_note_values(one_hot_phrase):\n",
    "    ''' 12 is 0, 13 is start, 14 is end '''\n",
    "    note_values = np.zeros((number_of_notes+2, 1))\n",
    "    for i in range(0, len(one_hot_phrase)):\n",
    "        index, = np.where(one_hot_phrase[i] == 1)\n",
    "        if(len(index) == 0):\n",
    "            continue\n",
    "        if(index[0] == 12):\n",
    "            note_values[i] = 0 \n",
    "        elif(index[0] == 13):\n",
    "            note_values[i] = -1\n",
    "        elif(index[0] == 14):\n",
    "            note_values[i] = -2\n",
    "        else:\n",
    "            note_values[i] = index[0]\n",
    "    return note_values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[-1.  0.  9.  8.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -2.]]\n[[-1.  1.  1.  1.  1.  1.  1.  1.  1. 11. 11. 11. 11. 11. 11. 11. 11. 10.\n  10. 10. 10. 10. 10. 10. 10. 11. 11. 11. 11. 11. 11. 11. 11. 11. 11. 11.\n  11. 11. 11. 11. 11. 11. 11. 11. 11. 11. 11. 11. 11. 11. 11. 11. 11. 11.\n  11. 11. 11. 11. 11. 11. 11. 11. 11. 11.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "number_of_notes = 64\n",
    "\n",
    "custom_input = np.zeros((1, number_of_notes+2, 15))\n",
    "custom_output = np.zeros((1, number_of_notes+2, 15))\n",
    "custom_input[0] = note_values_to_one_hot_phrase([36., 36., 36., 36., 36., 36., 36., 39., 39., 39., 39., 39., 39.,\n",
    "       39., 39., 40., 40., 40., 40., 40., 40., 40., 40., 40., 40., 40.,\n",
    "       40., 40., 40., 40., 40., 39., 39., 39., 39., 39., 39., 39., 39.,\n",
    "       39., 39., 39., 39., 39., 39., 39., 39., 42., 42., 42., 42., 42.,\n",
    "       42., 42., 42., 42., 42., 42., 42., 42., 42.])\n",
    "custom_output = decode_sequence(custom_input)\n",
    "\n",
    "print(one_hot_phrase_to_note_values(custom_input[0]).T)\n",
    "print(one_hot_phrase_to_note_values(custom_output).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.7 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "5b3ded1ccb95c1d9bd405e7b823d9e85424cde40fbb5985eb47e999ef50e15b4"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}